---
layout: post
title: "A way out of the Jar Hell"
summary: "TODO"
category: development
tags: [scala, java, community]
---
{% include JB/setup %}

TODO: point of view of the Scala/JVM developer

It can be argued that the single factor that makes modern development more 
productive is the extensive use of tons and tons of open source libraries.
What in other times would have required months of development is today a handful
of lines of code depending on a dozen libraries[^1].
However, this powerful practice carries the seeds of important problems that
can curtail its benefits.

[^1]: And it's transitive dependencies! It's not uncommon to have hundreds of them in a single small project.

## Library galore perils

There are many possible perils of the profuse use of libraries and most of them
are given short shrift by the development team as if they were not out
responsibility.

 * **Library licensing**. There are many kinds of software licences and more
   that one definition of open source out there. Some of the licenses impose
   restrictions on the systems those libraries integrates to (e.g. GPLv3) and
   we cannot equate *"I can download it from Maven central"* with *"I can use
   it freely"*.
   TODO: Is there any mechanism for this in mvn/ivy/sbt?

 * **Library quality**. Not all the code that is released as libraries has the
   same standards of quality. Even when having high standards of quality, the
   assumptions or the focus of the library can be far from the design of you
   application making you work around the library design doing circuitous
   designs. Sometimes we want a banana, but the library we have found has a
   giant gorilla holding the banana. Think about this gorilla as concepts
   unrelated with you application and bugs (in the library or its transitive
   dependencies).
  
   Adopting libraries should not be done blithely, but after a cost-benefit
   analysis. Remember the [Sturgeon's revelation][sturgeon]: 90% of anything,
   including libraries, is crap.
   
   [sturgeon]: https://en.wikipedia.org/wiki/Sturgeon's_law
   
 * **Security**.
   TODO: NPM incident with crypto
   TODO: has something similar happened with Java/Scala?
   
   [sbt-dependency-check]: https://github.com/albuch/sbt-dependency-check
   
 * **Compatibility issues**. Unlike the previous ones, this problem can't be
   overlooked because when we have a library compatibility problem, like the
   typical binary compatibility issue like the feared
   `IncompatibleClassChangeError` out code refuses to work. You can ignore
   that one of your libraries has a license you are violating but not fixing
   a conflict of versions is like spurring a dead horse. Way more about this in
   the next section.
   
All these problems get amplified by the fact that when we decide to marry one
library we are not marring just that library but all its family: potentially
many transitive dependencies. You need to check the licences of all those libs,
evaluate their quality, monitor its CVE's and pray for them not to have a
version conflict with the other libraries you are using.
 
## Compatibility problems

TODO: jar hell picture as one ring of Dante's inferno

* What is it? Binary compatibility problems and the "diamond" dependency
* Non-binary compatibility problems: if any assumption changes the code will
  crash/misbehave even if you find all the right classes and methods in place
* Huge amounts of heat dissipated in this problem (can't be ignored unlike  
  the previous ones)
* Mitigate this problem by having granular modules with a small number of
  dependencies
* Is OSGi a solution? Psech√©. Only allows you to isolate libraries that are
  effectively hidden (TODO: check about public dependencies in osgi).
  Also, many problems with reflection
* TODO: Java 11? modules. Some benefits but it's a long way until we see
  the benefits
* Typical solutions:
  * Bumping up and down some dependencies to make them compatible
  * Forking projects to align libraries (Note about having good conventions
  to not to confuse your coworkers)
  
## Is there any way out?

Is there any solution? Should we suffer these problems as a way to atone our
promiscuous library sins?

Lately I've been wasting quite some time impeded by binary compatibility
problems and I became close to convinced that they were an inevitable part
of the life of the Scala programmer very much like NPEs for the Java programmer.
But then some friend of mine reteeted this:

TODO: feno's tweet about Debian 10

A workable approach to these problems was hidden in plain sight!


* 
  * When I saw Debian 10 release announcement (TODO: link) I was thunderstruck
    by the revelation: Debian has been solving these problems for decades!
  * Premise: libraries (or "packages") are open source and we know under which
    license are released. That way we can guarantee that just complying licenses
    enter the distribution and we can apply patches on top the original code.
  * The "distribution" has different releases. Each release is build around
    specific versions of core libraries. For example: libc x.xx and linux series
    x.xx in Debian 9 and x.xx and series x.xx in Debian 10.
    Everything else is adapted to work with that core by maintaining a small
    set of patches that address compilation/configuration issues.
    The result are maintained packages. A package has:
    * A maintainer. To become a maintainer you need to gain the trust of the
      community and get your GPG key signed by some number of existing members
      of the community. It's very unlikely that a person like "the NPM hacker"
      will get to the same attack to Debian.
    * Machine-readable metadata used by the software installation/upgrading 
      tools (APT suite). Version, dependencies, license, upstream authors,
      maintainers, etc.
    * The set of patches. These are maintained in separate files from the
      upstream code and are also open source for anyone to use.
  * After a release is ready from prime time packages are frozen except for
    security upgrades. These are, by design, things you can trust to update
    automatically with confidence that nothing is going to break. Interfaces
    won't change, configuration formats won't change. You just get security
    patches. These are sometimes provided by the upstream developers and,
    other times by the Debian maintainers.
  * How a new release version is created? First, the core libraries are bumped and then
    the software around them gets updated, some packages are added or removed
    and problems arise and are fixed. After some time, it is reasonably clear
    that all included packages work well with each other and it is released.
  * What happens with closed software? It benefit greatly for this model of
    releases because you just need to compile your libraries/programs against
    each recent Debian release and provide a repository url. No need to create
    a binary that is statically linked against all libraries (this is analogous
    to the fat-jar anti-pattern).
  * What happens if I need the latest version of a library for a release of 
    Debian that has an older version? You can always compile it against what is
    shipped in that release. However, as this is very common, the work of
    changing dependencies and fixing compilation is shared in dedicated 
    "backport" repositories.
    
* Can I have this for Java/Scala?
  * Fury distributions: which part of this model is supported?
  
## Time to mature
  
It's a matter of maturity. Using so many libraries so liberally has multiplied
developer productivity to a large extent but without the restraint of some
curation culture like the one in Debian it's risks and practical problems might
cancel out the advantages of having access to this galore of functionality.
    
   
  
  
    
    
